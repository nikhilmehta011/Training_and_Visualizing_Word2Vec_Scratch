{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('npr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lowercasing ### \n",
    "df['Article'] = df['Article'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using correct apostrophe ###\n",
    "def replace_apostrophe(text):\n",
    "    apostrophe = re.compile(r\"â€™\")\n",
    "    return apostrophe.sub(r\"'\", text)\n",
    "\n",
    "df['Article'] = df['Article'].map(lambda x: replace_apostrophe(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing hashtag words: (#brexit, #dumpsterfyre) ###  \n",
    "def remove_hash_words(text):\n",
    "    hashtag_words = re.compile(r\"#[A-Za-z0-9]+\")\n",
    "    return hashtag_words.sub(r\"\", text)\n",
    "\n",
    "df['Article'] = df['Article'].map(lambda x: remove_hash_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Stopwords ###\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "\n",
    "    return \" \".join(text)\n",
    "\n",
    "df['Article'] = df['Article'].map(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Punctuation ###\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "df['Article'] = df['Article'].map(lambda x: remove_punct(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "def into_tokens(text):\n",
    "    tokens = TweetTokenizer().tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "df['Article'] = df['Article'].map(lambda x: into_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(df):\n",
    "    \n",
    "    corpus = []\n",
    "    \n",
    "    for x in df['Article']:\n",
    "        for i in x:\n",
    "            corpus.append(i)\n",
    "    \n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = create_corpus(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary and Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist = nltk.FreqDist(word for word in corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Vocabulary Size: \", len(fdist))\n",
    "print(\"Most frequet words: \", fdist.most_common(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
